{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEW-SQZoCYbT"
      },
      "source": [
        "# Definición del problema"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se desea entrenar un modelo que sea capaz de 'completar' una palabra a medio escribir, o proponer una corrección para una palabra ya escrita en caso de que la misma se encuentre mal escrita.\n",
        "\n",
        "Se utilizará un algoritmo de 'hallar la palabra incorrecta' para determinar si una palabra está escrita incorrectamente, de acuerdo a un lexicón construido con palabras extraídas de la página web de la RAE (disponible en https://github.com/JorgeDuenasLerin/diccionario-espanol-txt, actualizado en Mayo 2024)\n",
        "\n",
        "Además, se construirá una matriz de probabilidad con las palabras extraídas para que las recomendaciones de completado y corrección se realicen en función de la frecuencia de utilización de las palabras. El sistema será capaz de realizar estas funciones en Español.\n",
        "\n",
        "Se utilizarán textos para entrenarlo."
      ],
      "metadata": {
        "id": "9FcXCHksCbGB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estructura del modelo"
      ],
      "metadata": {
        "id": "_WMLpyK3Zci_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7SpmcbTWZhAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIQTHR1LCYbZ"
      },
      "source": [
        "# Datos de entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "NH6BNWm-CYbZ",
        "collapsed": true,
        "outputId": "b202d51b-ab2a-4faf-af8c-cad54dec19ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "753\n"
          ]
        }
      ],
      "source": [
        "#Extrayendo el texto\n",
        "txt_file = \"text_dump.txt\"\n",
        "\n",
        "lines: list[str] = []\n",
        "# complete_text: str = \"\"\n",
        "with open(txt_file, \"r\") as file:\n",
        "  for line in file:\n",
        "    if line != \"\\n\":\n",
        "      lines.append(line)\n",
        "      # complete_text += line\n",
        "\n",
        "# print(len(lines))\n",
        "# print(complete_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Formando la data de entrada y salida esperada\n",
        "complete_text: str = \"\"\n",
        "regex_specials = \"\"\"-—?¿\"'!¡:;.,()…“”/\"\"\"\n",
        "\n",
        "\n",
        "for paragraph in lines[6 : 747]:\n",
        "  clean_paragraph = \"\"\n",
        "  for char in paragraph:\n",
        "    if char not in regex_specials:\n",
        "      clean_paragraph += char\n",
        "\n",
        "  complete_text += clean_paragraph\n",
        "\n",
        "complete_text = complete_text.lower()\n",
        "\n",
        "\n",
        "#Construyendo la data de input, output y conjunto de tokens\n",
        "encoder_tokens: dict[str, int] = dict()\n",
        "decoder_tokens: dict[str, int] = dict()\n",
        "input_chars: list[str] = []\n",
        "output_chars: list[str] = []\n",
        "\n",
        "\n",
        "# input_chars.append(complete_text[0])\n",
        "\n",
        "#Llenar los inputs y outputs de manera escalonada\n",
        "for i in range(0, len(complete_text) - 1):\n",
        "  input_char = complete_text[i]\n",
        "\n",
        "  input_chars.append(input_char)\n",
        "  output_chars.append(complete_text[i + 1])\n",
        "\n",
        "  if input_char not in encoder_tokens:\n",
        "    index = len(encoder_tokens)\n",
        "    encoder_tokens[input_char] = index\n",
        "    decoder_tokens[index] = input_char\n",
        "\n",
        "\n",
        "# for i, pair in enumerate(zip(input_chars, output_chars)):\n",
        "#   print(pair)\n",
        "#   index += 1\n",
        "#   if index >= 100:\n",
        "#     break\n",
        "\n",
        "# for key, value in zip(encoder_tokens.keys(), encoder_tokens.values()):\n",
        "#   print(f\"Key: {key} | Value: {value}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "rHfyF-Xmu0ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Creando la matriz de caracteres\n",
        "\n",
        "input_size = len(input_chars)\n",
        "token_size = len(encoder_tokens)\n",
        "\n",
        "input_data = np.zeros((input_size, 1,token_size), dtype= \"float32\")\n",
        "# decoder_input_data = np.zeros((input_size, token_size), dtype= \"float32\")\n",
        "output_data = np.zeros((input_size, 1,token_size), dtype= \"float32\")\n",
        "\n",
        "\n",
        "for i, (input, output) in enumerate(zip(input_chars, output_chars)):\n",
        "  input_data[i, 0,encoder_tokens[input]] = 1.0\n",
        "  output_data[i, 0,encoder_tokens[output]] = 1.0"
      ],
      "metadata": {
        "id": "884DUN0lahf9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0VZpRHJCYbX"
      },
      "source": [
        "# Construción del modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import initializers\n",
        "\n",
        "neurons = 800"
      ],
      "metadata": {
        "id": "ttqLZYb3o2ad"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_initializer = initializers.RandomNormal(mean= 0.01, stddev= 0.08)\n",
        "\n",
        "encoder_inputs = keras.Input(shape= (None, token_size))\n",
        "encoder = keras.layers.LSTM(neurons, return_state= True, kernel_initializer= weight_initializer)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_inputs = keras.Input(shape= (None, token_size))\n",
        "\n",
        "decoder_lstm = keras.layers.LSTM(neurons, return_sequences= True, return_state= True, kernel_initializer= weight_initializer)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state= encoder_states)\n",
        "decoder_dense = keras.layers.Dense(token_size, activation= \"softmax\", kernel_initializer= weight_initializer )\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(optimizer= \"rmsprop\", loss= \"categorical_crossentropy\", metrics= [\"accuracy\"])"
      ],
      "metadata": {
        "id": "O3rey1t9pyk1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8irePKGLCYba"
      },
      "source": [
        "# Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([input_data, input_data], output_data, batch_size= 64, epochs= 200, validation_split= 0.3)\n",
        "\n",
        "model.save(\"s2s-Principito.keras\")"
      ],
      "metadata": {
        "id": "owd6bjCosH-2",
        "outputId": "8b37e244-9906-49a1-b784-6b7a5dce1e6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.2559 - loss: 2.6313 - val_accuracy: 0.2786 - val_loss: 2.3074\n",
            "Epoch 2/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2805 - loss: 2.2940 - val_accuracy: 0.2759 - val_loss: 2.2982\n",
            "Epoch 3/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2760 - loss: 2.2906 - val_accuracy: 0.2738 - val_loss: 2.2921\n",
            "Epoch 4/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2750 - loss: 2.2888 - val_accuracy: 0.2762 - val_loss: 2.2907\n",
            "Epoch 5/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2801 - loss: 2.2770 - val_accuracy: 0.2792 - val_loss: 2.2903\n",
            "Epoch 6/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2734 - loss: 2.2901 - val_accuracy: 0.2734 - val_loss: 2.2925\n",
            "Epoch 7/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2776 - loss: 2.2865 - val_accuracy: 0.2664 - val_loss: 2.2943\n",
            "Epoch 8/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2778 - loss: 2.2787 - val_accuracy: 0.2635 - val_loss: 2.2996\n",
            "Epoch 9/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2761 - loss: 2.2885 - val_accuracy: 0.2763 - val_loss: 2.2890\n",
            "Epoch 10/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2782 - loss: 2.2877 - val_accuracy: 0.2678 - val_loss: 2.2898\n",
            "Epoch 11/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2773 - loss: 2.2762 - val_accuracy: 0.2804 - val_loss: 2.2850\n",
            "Epoch 12/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.2747 - loss: 2.2836 - val_accuracy: 0.2745 - val_loss: 2.2895\n",
            "Epoch 13/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2763 - loss: 2.2912 - val_accuracy: 0.2805 - val_loss: 2.2893\n",
            "Epoch 14/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2764 - loss: 2.2830 - val_accuracy: 0.2697 - val_loss: 2.2922\n",
            "Epoch 15/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2774 - loss: 2.2796 - val_accuracy: 0.2796 - val_loss: 2.2919\n",
            "Epoch 16/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2792 - loss: 2.2809 - val_accuracy: 0.2790 - val_loss: 2.2898\n",
            "Epoch 17/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2790 - loss: 2.2674 - val_accuracy: 0.2763 - val_loss: 2.2856\n",
            "Epoch 18/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2736 - loss: 2.2902 - val_accuracy: 0.2768 - val_loss: 2.2881\n",
            "Epoch 19/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2742 - loss: 2.2888 - val_accuracy: 0.2825 - val_loss: 2.2910\n",
            "Epoch 20/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2779 - loss: 2.2789 - val_accuracy: 0.2732 - val_loss: 2.2868\n",
            "Epoch 21/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2765 - loss: 2.2767 - val_accuracy: 0.2613 - val_loss: 2.2906\n",
            "Epoch 22/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2710 - loss: 2.2881 - val_accuracy: 0.2686 - val_loss: 2.2959\n",
            "Epoch 23/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2777 - loss: 2.2843 - val_accuracy: 0.2721 - val_loss: 2.2930\n",
            "Epoch 24/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.2784 - loss: 2.2725 - val_accuracy: 0.2827 - val_loss: 2.2877\n",
            "Epoch 25/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2766 - loss: 2.2826 - val_accuracy: 0.2772 - val_loss: 2.2880\n",
            "Epoch 26/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2750 - loss: 2.2845 - val_accuracy: 0.2815 - val_loss: 2.2938\n",
            "Epoch 27/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2760 - loss: 2.2846 - val_accuracy: 0.2792 - val_loss: 2.2920\n",
            "Epoch 28/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2745 - loss: 2.2817 - val_accuracy: 0.2804 - val_loss: 2.2882\n",
            "Epoch 29/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2760 - loss: 2.2780 - val_accuracy: 0.2759 - val_loss: 2.2866\n",
            "Epoch 30/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2782 - loss: 2.2821 - val_accuracy: 0.2821 - val_loss: 2.2891\n",
            "Epoch 31/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2780 - loss: 2.2860 - val_accuracy: 0.2695 - val_loss: 2.2914\n",
            "Epoch 32/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2780 - loss: 2.2745 - val_accuracy: 0.2757 - val_loss: 2.2856\n",
            "Epoch 33/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2785 - loss: 2.2798 - val_accuracy: 0.2789 - val_loss: 2.2833\n",
            "Epoch 34/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2753 - loss: 2.2815 - val_accuracy: 0.2680 - val_loss: 2.2873\n",
            "Epoch 35/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.2737 - loss: 2.2821 - val_accuracy: 0.2748 - val_loss: 2.2881\n",
            "Epoch 36/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2769 - loss: 2.2830 - val_accuracy: 0.2690 - val_loss: 2.2905\n",
            "Epoch 37/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2798 - loss: 2.2705 - val_accuracy: 0.2620 - val_loss: 2.2969\n",
            "Epoch 38/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2763 - loss: 2.2834 - val_accuracy: 0.2822 - val_loss: 2.2906\n",
            "Epoch 39/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2797 - loss: 2.2773 - val_accuracy: 0.2811 - val_loss: 2.2910\n",
            "Epoch 40/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2737 - loss: 2.2935 - val_accuracy: 0.2795 - val_loss: 2.2881\n",
            "Epoch 41/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.2798 - loss: 2.2788 - val_accuracy: 0.2741 - val_loss: 2.2911\n",
            "Epoch 42/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2789 - loss: 2.2801 - val_accuracy: 0.2736 - val_loss: 2.2921\n",
            "Epoch 43/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2801 - loss: 2.2734 - val_accuracy: 0.2747 - val_loss: 2.2952\n",
            "Epoch 44/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2771 - loss: 2.2800 - val_accuracy: 0.2696 - val_loss: 2.2907\n",
            "Epoch 45/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2739 - loss: 2.2872 - val_accuracy: 0.2778 - val_loss: 2.2848\n",
            "Epoch 46/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2732 - loss: 2.2871 - val_accuracy: 0.2765 - val_loss: 2.2824\n",
            "Epoch 47/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2767 - loss: 2.2811 - val_accuracy: 0.2731 - val_loss: 2.2913\n",
            "Epoch 48/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2740 - loss: 2.2834 - val_accuracy: 0.2721 - val_loss: 2.2911\n",
            "Epoch 49/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2765 - loss: 2.2845 - val_accuracy: 0.2802 - val_loss: 2.2933\n",
            "Epoch 50/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2772 - loss: 2.2633 - val_accuracy: 0.2788 - val_loss: 2.2917\n",
            "Epoch 51/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2773 - loss: 2.2846 - val_accuracy: 0.2801 - val_loss: 2.2862\n",
            "Epoch 52/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2770 - loss: 2.2787 - val_accuracy: 0.2774 - val_loss: 2.2899\n",
            "Epoch 53/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2770 - loss: 2.2855 - val_accuracy: 0.2702 - val_loss: 2.2853\n",
            "Epoch 54/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2766 - loss: 2.2749 - val_accuracy: 0.2819 - val_loss: 2.2887\n",
            "Epoch 55/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2723 - loss: 2.2879 - val_accuracy: 0.2770 - val_loss: 2.2880\n",
            "Epoch 56/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2760 - loss: 2.2844 - val_accuracy: 0.2724 - val_loss: 2.2884\n",
            "Epoch 57/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2797 - loss: 2.2747 - val_accuracy: 0.2692 - val_loss: 2.2882\n",
            "Epoch 58/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2784 - loss: 2.2712 - val_accuracy: 0.2792 - val_loss: 2.2846\n",
            "Epoch 59/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.2746 - loss: 2.2807 - val_accuracy: 0.2746 - val_loss: 2.2897\n",
            "Epoch 60/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2781 - loss: 2.2781 - val_accuracy: 0.2767 - val_loss: 2.2872\n",
            "Epoch 61/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2816 - loss: 2.2707 - val_accuracy: 0.2722 - val_loss: 2.2902\n",
            "Epoch 62/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2768 - loss: 2.2789 - val_accuracy: 0.2741 - val_loss: 2.2958\n",
            "Epoch 63/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2762 - loss: 2.2809 - val_accuracy: 0.2761 - val_loss: 2.2900\n",
            "Epoch 64/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2763 - loss: 2.2795 - val_accuracy: 0.2802 - val_loss: 2.2885\n",
            "Epoch 65/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2791 - loss: 2.2839 - val_accuracy: 0.2731 - val_loss: 2.2918\n",
            "Epoch 66/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.2740 - loss: 2.2889 - val_accuracy: 0.2790 - val_loss: 2.2864\n",
            "Epoch 67/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2750 - loss: 2.2863 - val_accuracy: 0.2748 - val_loss: 2.2965\n",
            "Epoch 68/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2786 - loss: 2.2777 - val_accuracy: 0.2777 - val_loss: 2.2893\n",
            "Epoch 69/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2764 - loss: 2.2807 - val_accuracy: 0.2734 - val_loss: 2.2875\n",
            "Epoch 70/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2772 - loss: 2.2764 - val_accuracy: 0.2767 - val_loss: 2.2855\n",
            "Epoch 71/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2796 - loss: 2.2731 - val_accuracy: 0.2670 - val_loss: 2.2879\n",
            "Epoch 72/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2810 - loss: 2.2786 - val_accuracy: 0.2801 - val_loss: 2.2891\n",
            "Epoch 73/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2765 - loss: 2.2744 - val_accuracy: 0.2720 - val_loss: 2.2841\n",
            "Epoch 74/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2754 - loss: 2.2781 - val_accuracy: 0.2772 - val_loss: 2.2881\n",
            "Epoch 75/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2764 - loss: 2.2782 - val_accuracy: 0.2792 - val_loss: 2.2868\n",
            "Epoch 76/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2773 - loss: 2.2716 - val_accuracy: 0.2824 - val_loss: 2.2872\n",
            "Epoch 77/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.2813 - loss: 2.2699 - val_accuracy: 0.2757 - val_loss: 2.2912\n",
            "Epoch 78/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2771 - loss: 2.2757 - val_accuracy: 0.2703 - val_loss: 2.2879\n",
            "Epoch 79/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2764 - loss: 2.2739 - val_accuracy: 0.2763 - val_loss: 2.2863\n",
            "Epoch 80/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2805 - loss: 2.2758 - val_accuracy: 0.2731 - val_loss: 2.2879\n",
            "Epoch 81/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2762 - loss: 2.2829 - val_accuracy: 0.2799 - val_loss: 2.2882\n",
            "Epoch 82/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2709 - loss: 2.2892 - val_accuracy: 0.2827 - val_loss: 2.2849\n",
            "Epoch 83/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2770 - loss: 2.2721 - val_accuracy: 0.2726 - val_loss: 2.2878\n",
            "Epoch 84/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2754 - loss: 2.2823 - val_accuracy: 0.2730 - val_loss: 2.2907\n",
            "Epoch 85/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2777 - loss: 2.2787 - val_accuracy: 0.2827 - val_loss: 2.2863\n",
            "Epoch 86/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2788 - loss: 2.2763 - val_accuracy: 0.2736 - val_loss: 2.2945\n",
            "Epoch 87/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2735 - loss: 2.2731 - val_accuracy: 0.2765 - val_loss: 2.2859\n",
            "Epoch 88/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2760 - loss: 2.2750 - val_accuracy: 0.2792 - val_loss: 2.2857\n",
            "Epoch 89/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2773 - loss: 2.2764 - val_accuracy: 0.2743 - val_loss: 2.2871\n",
            "Epoch 90/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2803 - loss: 2.2683 - val_accuracy: 0.2707 - val_loss: 2.2821\n",
            "Epoch 91/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.2781 - loss: 2.2780 - val_accuracy: 0.2774 - val_loss: 2.2847\n",
            "Epoch 92/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2827 - loss: 2.2671 - val_accuracy: 0.2806 - val_loss: 2.2883\n",
            "Epoch 93/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2761 - loss: 2.2704 - val_accuracy: 0.2779 - val_loss: 2.2867\n",
            "Epoch 94/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2791 - loss: 2.2672 - val_accuracy: 0.2792 - val_loss: 2.2845\n",
            "Epoch 95/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2771 - loss: 2.2737 - val_accuracy: 0.2720 - val_loss: 2.2887\n",
            "Epoch 96/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2740 - loss: 2.2728 - val_accuracy: 0.2824 - val_loss: 2.2865\n",
            "Epoch 97/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2758 - loss: 2.2823 - val_accuracy: 0.2696 - val_loss: 2.2839\n",
            "Epoch 98/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2758 - loss: 2.2713 - val_accuracy: 0.2775 - val_loss: 2.2853\n",
            "Epoch 99/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2782 - loss: 2.2771 - val_accuracy: 0.2737 - val_loss: 2.2852\n",
            "Epoch 100/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2764 - loss: 2.2782 - val_accuracy: 0.2740 - val_loss: 2.2883\n",
            "Epoch 101/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2793 - loss: 2.2604 - val_accuracy: 0.2726 - val_loss: 2.2871\n",
            "Epoch 102/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2759 - loss: 2.2752 - val_accuracy: 0.2815 - val_loss: 2.2845\n",
            "Epoch 103/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2833 - loss: 2.2677 - val_accuracy: 0.2794 - val_loss: 2.2855\n",
            "Epoch 104/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2759 - loss: 2.2761 - val_accuracy: 0.2817 - val_loss: 2.2853\n",
            "Epoch 105/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2734 - loss: 2.2816 - val_accuracy: 0.2799 - val_loss: 2.2855\n",
            "Epoch 106/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2742 - loss: 2.2814 - val_accuracy: 0.2733 - val_loss: 2.2887\n",
            "Epoch 107/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2764 - loss: 2.2808 - val_accuracy: 0.2764 - val_loss: 2.2875\n",
            "Epoch 108/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2787 - loss: 2.2721 - val_accuracy: 0.2739 - val_loss: 2.2868\n",
            "Epoch 109/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2780 - loss: 2.2750 - val_accuracy: 0.2669 - val_loss: 2.2881\n",
            "Epoch 110/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2813 - loss: 2.2737 - val_accuracy: 0.2797 - val_loss: 2.2849\n",
            "Epoch 111/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2736 - loss: 2.2752 - val_accuracy: 0.2777 - val_loss: 2.2882\n",
            "Epoch 112/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2819 - loss: 2.2763 - val_accuracy: 0.2727 - val_loss: 2.2883\n",
            "Epoch 113/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2796 - loss: 2.2709 - val_accuracy: 0.2712 - val_loss: 2.2889\n",
            "Epoch 114/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2757 - loss: 2.2780 - val_accuracy: 0.2741 - val_loss: 2.2896\n",
            "Epoch 115/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2798 - loss: 2.2756 - val_accuracy: 0.2751 - val_loss: 2.2916\n",
            "Epoch 116/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2866 - loss: 2.2695 - val_accuracy: 0.2831 - val_loss: 2.2870\n",
            "Epoch 117/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2774 - loss: 2.2753 - val_accuracy: 0.2660 - val_loss: 2.2837\n",
            "Epoch 118/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2797 - loss: 2.2670 - val_accuracy: 0.2689 - val_loss: 2.2880\n",
            "Epoch 119/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2796 - loss: 2.2798 - val_accuracy: 0.2749 - val_loss: 2.2881\n",
            "Epoch 120/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2816 - loss: 2.2676 - val_accuracy: 0.2753 - val_loss: 2.2872\n",
            "Epoch 121/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2763 - loss: 2.2776 - val_accuracy: 0.2753 - val_loss: 2.2843\n",
            "Epoch 122/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2788 - loss: 2.2760 - val_accuracy: 0.2796 - val_loss: 2.2870\n",
            "Epoch 123/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2742 - loss: 2.2835 - val_accuracy: 0.2748 - val_loss: 2.2932\n",
            "Epoch 124/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2775 - loss: 2.2730 - val_accuracy: 0.2771 - val_loss: 2.2948\n",
            "Epoch 125/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2756 - loss: 2.2756 - val_accuracy: 0.2800 - val_loss: 2.2858\n",
            "Epoch 126/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2765 - loss: 2.2747 - val_accuracy: 0.2765 - val_loss: 2.2879\n",
            "Epoch 127/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2778 - loss: 2.2835 - val_accuracy: 0.2731 - val_loss: 2.2876\n",
            "Epoch 128/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2732 - loss: 2.2774 - val_accuracy: 0.2735 - val_loss: 2.2890\n",
            "Epoch 129/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2762 - loss: 2.2783 - val_accuracy: 0.2801 - val_loss: 2.2921\n",
            "Epoch 130/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2769 - loss: 2.2747 - val_accuracy: 0.2740 - val_loss: 2.2852\n",
            "Epoch 131/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.2765 - loss: 2.2769 - val_accuracy: 0.2832 - val_loss: 2.2924\n",
            "Epoch 132/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2781 - loss: 2.2767 - val_accuracy: 0.2719 - val_loss: 2.2907\n",
            "Epoch 133/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2772 - loss: 2.2768 - val_accuracy: 0.2791 - val_loss: 2.2887\n",
            "Epoch 134/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2762 - loss: 2.2767 - val_accuracy: 0.2628 - val_loss: 2.2953\n",
            "Epoch 135/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2753 - loss: 2.2807 - val_accuracy: 0.2730 - val_loss: 2.2842\n",
            "Epoch 136/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2805 - loss: 2.2779 - val_accuracy: 0.2756 - val_loss: 2.2875\n",
            "Epoch 137/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2731 - loss: 2.2746 - val_accuracy: 0.2761 - val_loss: 2.2905\n",
            "Epoch 138/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2774 - loss: 2.2778 - val_accuracy: 0.2804 - val_loss: 2.2975\n",
            "Epoch 139/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2778 - loss: 2.2705 - val_accuracy: 0.2794 - val_loss: 2.2899\n",
            "Epoch 140/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2781 - loss: 2.2829 - val_accuracy: 0.2796 - val_loss: 2.2900\n",
            "Epoch 141/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2800 - loss: 2.2750 - val_accuracy: 0.2752 - val_loss: 2.2970\n",
            "Epoch 142/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2758 - loss: 2.2796 - val_accuracy: 0.2770 - val_loss: 2.2917\n",
            "Epoch 143/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2819 - loss: 2.2736 - val_accuracy: 0.2805 - val_loss: 2.2876\n",
            "Epoch 144/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2800 - loss: 2.2736 - val_accuracy: 0.2740 - val_loss: 2.2910\n",
            "Epoch 145/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2804 - loss: 2.2717 - val_accuracy: 0.2796 - val_loss: 2.2859\n",
            "Epoch 146/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2758 - loss: 2.2811 - val_accuracy: 0.2818 - val_loss: 2.2913\n",
            "Epoch 147/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2787 - loss: 2.2724 - val_accuracy: 0.2819 - val_loss: 2.2930\n",
            "Epoch 148/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2755 - loss: 2.2798 - val_accuracy: 0.2754 - val_loss: 2.2954\n",
            "Epoch 149/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2767 - loss: 2.2806 - val_accuracy: 0.2784 - val_loss: 2.2905\n",
            "Epoch 150/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2781 - loss: 2.2713 - val_accuracy: 0.2792 - val_loss: 2.2912\n",
            "Epoch 151/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2769 - loss: 2.2802 - val_accuracy: 0.2762 - val_loss: 2.2912\n",
            "Epoch 152/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2736 - loss: 2.2800 - val_accuracy: 0.2747 - val_loss: 2.2953\n",
            "Epoch 153/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2742 - loss: 2.2857 - val_accuracy: 0.2731 - val_loss: 2.2919\n",
            "Epoch 154/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2790 - loss: 2.2740 - val_accuracy: 0.2705 - val_loss: 2.2887\n",
            "Epoch 155/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2769 - loss: 2.2758 - val_accuracy: 0.2800 - val_loss: 2.2885\n",
            "Epoch 156/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2759 - loss: 2.2787 - val_accuracy: 0.2805 - val_loss: 2.2891\n",
            "Epoch 157/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2764 - loss: 2.2671 - val_accuracy: 0.2766 - val_loss: 2.2880\n",
            "Epoch 158/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2751 - loss: 2.2878 - val_accuracy: 0.2711 - val_loss: 2.2958\n",
            "Epoch 159/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2812 - loss: 2.2728 - val_accuracy: 0.2710 - val_loss: 2.2888\n",
            "Epoch 160/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2793 - loss: 2.2755 - val_accuracy: 0.2700 - val_loss: 2.2911\n",
            "Epoch 161/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2789 - loss: 2.2679 - val_accuracy: 0.2779 - val_loss: 2.2918\n",
            "Epoch 162/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2763 - loss: 2.2713 - val_accuracy: 0.2792 - val_loss: 2.2959\n",
            "Epoch 163/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2789 - loss: 2.2776 - val_accuracy: 0.2764 - val_loss: 2.2913\n",
            "Epoch 164/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2795 - loss: 2.2820 - val_accuracy: 0.2763 - val_loss: 2.2932\n",
            "Epoch 165/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2812 - loss: 2.2634 - val_accuracy: 0.2723 - val_loss: 2.2903\n",
            "Epoch 166/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2792 - loss: 2.2768 - val_accuracy: 0.2722 - val_loss: 2.2906\n",
            "Epoch 167/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2832 - loss: 2.2751 - val_accuracy: 0.2798 - val_loss: 2.2878\n",
            "Epoch 168/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2805 - loss: 2.2756 - val_accuracy: 0.2715 - val_loss: 2.2954\n",
            "Epoch 169/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.2789 - loss: 2.2762 - val_accuracy: 0.2775 - val_loss: 2.2913\n",
            "Epoch 170/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2812 - loss: 2.2712 - val_accuracy: 0.2764 - val_loss: 2.2906\n",
            "Epoch 171/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2810 - loss: 2.2720 - val_accuracy: 0.2678 - val_loss: 2.3026\n",
            "Epoch 172/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2763 - loss: 2.2777 - val_accuracy: 0.2679 - val_loss: 2.2977\n",
            "Epoch 173/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2742 - loss: 2.2809 - val_accuracy: 0.2794 - val_loss: 2.2962\n",
            "Epoch 174/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2779 - loss: 2.2831 - val_accuracy: 0.2774 - val_loss: 2.2889\n",
            "Epoch 175/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2773 - loss: 2.2849 - val_accuracy: 0.2770 - val_loss: 2.2929\n",
            "Epoch 176/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2788 - loss: 2.2688 - val_accuracy: 0.2683 - val_loss: 2.2895\n",
            "Epoch 177/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2763 - loss: 2.2894 - val_accuracy: 0.2783 - val_loss: 2.2900\n",
            "Epoch 178/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2795 - loss: 2.2836 - val_accuracy: 0.2676 - val_loss: 2.2991\n",
            "Epoch 179/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.2738 - loss: 2.2941 - val_accuracy: 0.2809 - val_loss: 2.2932\n",
            "Epoch 180/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2795 - loss: 2.2759 - val_accuracy: 0.2661 - val_loss: 2.2934\n",
            "Epoch 181/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.2758 - loss: 2.2814 - val_accuracy: 0.2820 - val_loss: 2.2957\n",
            "Epoch 182/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2796 - loss: 2.2754 - val_accuracy: 0.2796 - val_loss: 2.2930\n",
            "Epoch 183/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.2760 - loss: 2.2779 - val_accuracy: 0.2794 - val_loss: 2.2972\n",
            "Epoch 184/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2790 - loss: 2.2834 - val_accuracy: 0.2769 - val_loss: 2.2939\n",
            "Epoch 185/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2766 - loss: 2.2816 - val_accuracy: 0.2753 - val_loss: 2.2978\n",
            "Epoch 186/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.2789 - loss: 2.2758 - val_accuracy: 0.2776 - val_loss: 2.2936\n",
            "Epoch 187/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2758 - loss: 2.2770 - val_accuracy: 0.2677 - val_loss: 2.3069\n",
            "Epoch 188/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2770 - loss: 2.2761 - val_accuracy: 0.2762 - val_loss: 2.2945\n",
            "Epoch 189/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2762 - loss: 2.2777 - val_accuracy: 0.2785 - val_loss: 2.2999\n",
            "Epoch 190/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2754 - loss: 2.2863 - val_accuracy: 0.2709 - val_loss: 2.3013\n",
            "Epoch 191/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2778 - loss: 2.2846 - val_accuracy: 0.2718 - val_loss: 2.2931\n",
            "Epoch 192/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2735 - loss: 2.2815 - val_accuracy: 0.2796 - val_loss: 2.2962\n",
            "Epoch 193/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2767 - loss: 2.2768 - val_accuracy: 0.2761 - val_loss: 2.3055\n",
            "Epoch 194/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2737 - loss: 2.2770 - val_accuracy: 0.2807 - val_loss: 2.2986\n",
            "Epoch 195/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2776 - loss: 2.2858 - val_accuracy: 0.2744 - val_loss: 2.3017\n",
            "Epoch 196/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2776 - loss: 2.2908 - val_accuracy: 0.2709 - val_loss: 2.2967\n",
            "Epoch 197/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2829 - loss: 2.2796 - val_accuracy: 0.2758 - val_loss: 2.3004\n",
            "Epoch 198/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.2805 - loss: 2.2867 - val_accuracy: 0.2763 - val_loss: 2.2929\n",
            "Epoch 199/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.2766 - loss: 2.2792 - val_accuracy: 0.2725 - val_loss: 2.2920\n",
            "Epoch 200/200\n",
            "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.2806 - loss: 2.2699 - val_accuracy: 0.2574 - val_loss: 2.3099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD6SIafXCYbb"
      },
      "source": [
        "# Evaluación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "z7UV-B3eCYbb",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(\"s2s-Principito.keras\")\n",
        "\n",
        "encoder_inputs = model.input[0]\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]\n",
        "decoder_state_inputs = [keras.Input(shape= (neurons,)), keras.Input(shape= (neurons,))]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(decoder_inputs, initial_state= decoder_state_inputs)\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "def decode_word(input_char: str) -> str:\n",
        "  data = np.zeros((1, 1, token_size))\n",
        "  data[0, 0, encoder_tokens[input_char]] = 1.0\n",
        "\n",
        "  state_value = encoder_model.predict(data)\n",
        "\n",
        "  target_sequence = np.zeros((1, 1, token_size))\n",
        "  target_sequence[0,0, encoder_tokens[input_char]] = 1.0\n",
        "\n",
        "  decoded_word = input_char\n",
        "  sampled_char = \"\"\n",
        "  failsafe = 0\n",
        "  while sampled_char != \" \" and failsafe < 25:\n",
        "    failsafe += 1\n",
        "    output_tokens, h, c = decoder_model.predict([target_sequence] + state_value)\n",
        "\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = decoder_tokens[sampled_token_index]\n",
        "    decoded_word += sampled_char\n",
        "\n",
        "    target_sequence = np.zeros((1, 1, token_size))\n",
        "    target_sequence[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "    state_value = [h, c]\n",
        "\n",
        "  return decoded_word\n",
        "\n",
        "\n",
        "# sequence = input_data[1 : 2]\n",
        "# print(decoder_tokens[np.argmax(input_data[1, -1, :])])\n",
        "\n",
        "# # Define the shape of the decoder input explicitly\n",
        "# decoder_input_shape = (sequence.shape[0], sequence.shape[1], token_size)\n",
        "# # Assuming token_size is defined in your code\n",
        "\n",
        "# # Create the decoder input with the defined shape\n",
        "# decoder_input = output_data[1 : 2]\n",
        "# i = 0\n",
        "# decoded_char = \"\"\n",
        "# while decoded_char != \" \" and i < 25:\n",
        "#   i += 1\n",
        "#   # Now, predict using the model\n",
        "#   output_tokens = model.predict([sequence, decoder_input])\n",
        "\n",
        "#   token_index = np.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "#   decoded_char = decoder_tokens[token_index]\n",
        "\n",
        "#   print(decoded_char)\n",
        "\n",
        "#   sequence[0, 0, token_index] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_word = decode_word(\"j\")\n",
        "\n",
        "print(predicted_word)"
      ],
      "metadata": {
        "id": "59EVitGEgbDr",
        "outputId": "62f31b71-fc05-4005-dc8d-0d393b094b47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "jo1hhh \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}