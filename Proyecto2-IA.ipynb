{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEW-SQZoCYbT"
      },
      "source": [
        "# Definición del problema"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se desea entrenar un modelo que sea capaz de 'completar' una palabra a medio escribir, o proponer una corrección para una palabra ya escrita en caso de que la misma se encuentre mal escrita.\n",
        "\n",
        "Se utilizará un algoritmo de 'hallar la palabra incorrecta' para determinar si una palabra está escrita incorrectamente, de acuerdo a un lexicón construido con palabras extraídas de la página web de la RAE (disponible en https://github.com/JorgeDuenasLerin/diccionario-espanol-txt, actualizado en Mayo 2024)\n",
        "\n",
        "Además, se construirá una matriz de probabilidad con las palabras extraídas para que las recomendaciones de completado y corrección se realicen en función de la frecuencia de utilización de las palabras. El sistema será capaz de realizar estas funciones en Español.\n",
        "\n",
        "Se utilizarán textos para entrenarlo."
      ],
      "metadata": {
        "id": "9FcXCHksCbGB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0VZpRHJCYbX"
      },
      "source": [
        "# Estructura del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "ou1izJryCYbY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importacion de Librerias"
      ],
      "metadata": {
        "id": "Zxrx98HjngrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import keras as kr\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout"
      ],
      "metadata": {
        "id": "R0_I7z3pnlT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIQTHR1LCYbZ"
      },
      "source": [
        "# Datos de entrada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "NH6BNWm-CYbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82246a17-5fc0-4c21-e2f4-9c1873870309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total line count: 778\n",
            "Total character count: 78701\n"
          ]
        }
      ],
      "source": [
        "# Extract text from Spanish book converted into txt format\n",
        "txt_file = \"text_dump.txt\"\n",
        "\n",
        "lines: list[str] = []\n",
        "with open(txt_file, 'r', encoding=\"UTF-8\") as file:\n",
        "  for line in file:\n",
        "    if line != \"\\n\": #Do not include empty lines in text digest\n",
        "      lines.append(line)\n",
        "\n",
        "#As of this point, 'lines' variable should hold the full length of the txt file\n",
        "print(\"Total line count:\", len(lines))\n",
        "print(\"Total character count:\", sum([len(item) for item in lines]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract used vocabulary and construct encode/decode dictionaries\n",
        "full_txt_str: str = \"\"\n",
        "vocab: list[str] = []\n",
        "acc = 0 #Used to print partial progress of the operation\n",
        "big_acc = 1 #Same as above\n",
        "for paragraph in lines[31:14346]: #Do not consider index, acknowledgements, appendix, etc etc (i.e. only consider main story block for training)\n",
        "  full_txt_str += paragraph\n",
        "  for char in paragraph:\n",
        "    if char not in vocab:\n",
        "      vocab.append(char)\n",
        "  #Print partial progress\n",
        "  acc += 1\n",
        "  if (acc >= (14346-31)*0.2):\n",
        "    print(f\"Vocabulary {20*big_acc}% built\")\n",
        "    acc = 0\n",
        "    big_acc += 1\n",
        "vocab.sort()\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "encode_keys:dict[str,int] = {}\n",
        "decode_keys: dict[int, str] = {}\n",
        "for index, char in enumerate(vocab):\n",
        "  encode_keys[char] = index\n",
        "  decode_keys[index] = char\n",
        "\n",
        "#As of this point, the full vocabulary should be indexed\n",
        "print(\"Total unique characters:\", vocab_size)\n",
        "print(\"Total encode/decode dictionary keys:\", len(encode_keys.keys()),\"|\", len(decode_keys.keys()))\n",
        "print(\"Key list\\n\",encode_keys.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzR18gLGE5B0",
        "outputId": "5d96caef-89b0-4426-c9da-cd727a9b35db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique characters: 87\n",
            "Total encode/decode dictionary keys: 87 | 87\n",
            "Key list\n",
            " dict_keys(['\\n', ' ', '!', '\"', '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '5', '6', '7', '8', '9', ':', ';', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '¿', 'Á', 'Ú', 'á', 'é', 'í', 'ñ', 'ó', 'ú', 'ü', '—', '“', '”', '…'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct input/output data for LSTM network\n",
        "seq_length = 50\n",
        "input_seqs: list[list[float]] = []\n",
        "output_seqs: list[float] = []\n",
        "acc = 0 #Used to print partial progress of the operation\n",
        "big_acc = 1 #Same as above\n",
        "\n",
        "current:list[float] = []\n",
        "for char in full_txt_str:\n",
        "  if (len(current) >= seq_length):\n",
        "    input_seqs.append(current.copy())\n",
        "    output_seqs.append(encode_keys[char])\n",
        "    current = current[1:] #Remove first element\n",
        "  current.append(encode_keys[char])\n",
        "  #Print partial progress\n",
        "  acc += 1\n",
        "  if (acc >= len(full_txt_str)*0.2):\n",
        "    print(f\"IO data {20*big_acc}% built\")\n",
        "    acc = 0\n",
        "    big_acc += 1\n",
        "\n",
        "#Normalize input sequences\n",
        "normal_input_seqs: list[list[float]] = []\n",
        "for row in input_seqs:\n",
        "  normal_input_seqs.append([item/(vocab_size - 1) for item in row])\n",
        "print(\"Data normalization done\")\n",
        "\n",
        "#Construct arrays from data used\n",
        "train_data: np.ndarray = np.array([np.array(row) for row in normal_input_seqs])\n",
        "train_tags: np.ndarray = np.array([np.zeros(vocab_size) for item in output_seqs])\n",
        "for index, value in enumerate(output_seqs):\n",
        "  train_tags[index][value] = 1.0\n",
        "\n",
        "#As of this point, the full set of training data has been built\n",
        "print(\"Train shape:\", train_data.shape)\n",
        "print(\"Tags shape:\", train_tags.shape)\n",
        "print(\"First 20 steps\")\n",
        "acc = 0\n",
        "for data,tag in zip(train_data, train_tags):\n",
        "  print(acc+1)\n",
        "  print(data)\n",
        "  print(tag)\n",
        "  acc += 1\n",
        "  if (acc >= 20):\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "w3qZR9S7khoH",
        "outputId": "43342f2e-9f72-4d2b-9658-bbe3e056ecb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IO data 20% built\n",
            "IO data 40% built\n",
            "IO data 60% built\n",
            "IO data 80% built\n",
            "IO data 100% built\n",
            "Data normalization done\n",
            "Train shape: (73835, 5)\n",
            "Tags shape: (73835, 87)\n",
            "First 20 steps\n",
            "1\n",
            "[0.96511628 0.8372093  0.43023256 0.69767442 0.73255814]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "2\n",
            "[0.8372093  0.43023256 0.69767442 0.73255814 0.01162791]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "3\n",
            "[0.43023256 0.69767442 0.73255814 0.01162791 0.60465116]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "4\n",
            "[0.69767442 0.73255814 0.01162791 0.60465116 0.54651163]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "5\n",
            "[0.73255814 0.01162791 0.60465116 0.54651163 0.77906977]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "6\n",
            "[0.01162791 0.60465116 0.54651163 0.77906977 0.69767442]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "7\n",
            "[0.60465116 0.54651163 0.77906977 0.69767442 0.73255814]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            "8\n",
            "[0.54651163 0.77906977 0.69767442 0.73255814 1.        ]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "9\n",
            "[0.77906977 0.69767442 0.73255814 1.         0.01162791]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "10\n",
            "[0.69767442 0.73255814 1.         0.01162791 0.70930233]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "11\n",
            "[0.73255814 1.         0.01162791 0.70930233 0.90697674]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "12\n",
            "[1.         0.01162791 0.70930233 0.90697674 0.68604651]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "13\n",
            "[0.01162791 0.70930233 0.90697674 0.68604651 0.75581395]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "14\n",
            "[0.70930233 0.90697674 0.68604651 0.75581395 0.54651163]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "15\n",
            "[0.90697674 0.68604651 0.75581395 0.54651163 0.6744186 ]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "16\n",
            "[0.68604651 0.75581395 0.54651163 0.6744186  0.59302326]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "17\n",
            "[0.75581395 0.54651163 0.6744186  0.59302326 0.01162791]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "18\n",
            "[0.54651163 0.6744186  0.59302326 0.01162791 0.76744186]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "19\n",
            "[0.6744186  0.59302326 0.01162791 0.76744186 0.68604651]\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "20\n",
            "[0.59302326 0.01162791 0.76744186 0.68604651 0.01162791]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Construcción del modelo"
      ],
      "metadata": {
        "id": "OPUwYDmX97It"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"savestate.keras\"\n",
        "isNew = True\n",
        "\n",
        "vect_model = None\n",
        "if (isNew):\n",
        "  vect_model = Sequential()\n",
        "  vect_model.add(kr.Input(shape=(seq_length,1)))\n",
        "  vect_model.add(LSTM(256)) #Add dropout?\n",
        "  vect_model.add(Dropout(0.2))\n",
        "  vect_model.add(Dense(vocab_size, activation=\"softmax\"))\n",
        "  vect_model.compile(loss=\"categorical_crossentropy\",optimizer=\"rmsprop\")\n",
        "else:\n",
        "  kr.models.load_model(filename)"
      ],
      "metadata": {
        "id": "uBjJAtCr996s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8irePKGLCYba"
      },
      "source": [
        "# Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_ct:int = 0\n",
        "train_length:int = 200\n",
        "\n",
        "predict:kr.History = vect_model.fit(train_data, train_tags, batch_size = 64,epochs = train_length)\n",
        "epoch_ct += train_length\n",
        "state_filename = \"state_\" + str(epoch_ct) + \"_28Nov.keras\"\n",
        "vect_model.save(state_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62DcwYfoECfY",
        "outputId": "ba35a4f3-6fab-47f5-d36a-7a5a62016016",
        "collapsed": true
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5585 - loss: 1.3584\n",
            "Epoch 2/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5596 - loss: 1.3606\n",
            "Epoch 3/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5584 - loss: 1.3603\n",
            "Epoch 4/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5556 - loss: 1.3682\n",
            "Epoch 5/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5591 - loss: 1.3610\n",
            "Epoch 6/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5580 - loss: 1.3586\n",
            "Epoch 7/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5606 - loss: 1.3559\n",
            "Epoch 8/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5568 - loss: 1.3690\n",
            "Epoch 9/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5586 - loss: 1.3659\n",
            "Epoch 10/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5564 - loss: 1.3621\n",
            "Epoch 11/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5539 - loss: 1.3706\n",
            "Epoch 12/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5575 - loss: 1.3653\n",
            "Epoch 13/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5602 - loss: 1.3623\n",
            "Epoch 14/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5556 - loss: 1.3697\n",
            "Epoch 15/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5572 - loss: 1.3662\n",
            "Epoch 16/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5604 - loss: 1.3604\n",
            "Epoch 17/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5573 - loss: 1.3641\n",
            "Epoch 18/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5551 - loss: 1.3693\n",
            "Epoch 19/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5561 - loss: 1.3657\n",
            "Epoch 20/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5593 - loss: 1.3671\n",
            "Epoch 21/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5557 - loss: 1.3724\n",
            "Epoch 22/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5574 - loss: 1.3671\n",
            "Epoch 23/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5592 - loss: 1.3712\n",
            "Epoch 24/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5562 - loss: 1.3706\n",
            "Epoch 25/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5610 - loss: 1.3659\n",
            "Epoch 26/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5601 - loss: 1.3596\n",
            "Epoch 27/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5605 - loss: 1.3623\n",
            "Epoch 28/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5607 - loss: 1.3619\n",
            "Epoch 29/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5588 - loss: 1.3671\n",
            "Epoch 30/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5576 - loss: 1.3712\n",
            "Epoch 31/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5604 - loss: 1.3592\n",
            "Epoch 32/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5586 - loss: 1.3558\n",
            "Epoch 33/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5590 - loss: 1.3614\n",
            "Epoch 34/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5585 - loss: 1.3579\n",
            "Epoch 35/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5580 - loss: 1.3640\n",
            "Epoch 36/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5602 - loss: 1.3564\n",
            "Epoch 37/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5543 - loss: 1.3687\n",
            "Epoch 38/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5611 - loss: 1.3585\n",
            "Epoch 39/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5574 - loss: 1.3741\n",
            "Epoch 40/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5622 - loss: 1.3597\n",
            "Epoch 41/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5585 - loss: 1.3620\n",
            "Epoch 42/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5646 - loss: 1.3473\n",
            "Epoch 43/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5633 - loss: 1.3654\n",
            "Epoch 44/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5651 - loss: 1.3625\n",
            "Epoch 45/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5585 - loss: 1.3652\n",
            "Epoch 46/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5622 - loss: 1.3614\n",
            "Epoch 47/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5606 - loss: 1.3618\n",
            "Epoch 48/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5558 - loss: 1.3670\n",
            "Epoch 49/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5577 - loss: 1.3737\n",
            "Epoch 50/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5580 - loss: 1.3588\n",
            "Epoch 51/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5586 - loss: 1.3614\n",
            "Epoch 52/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5540 - loss: 1.3742\n",
            "Epoch 53/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5587 - loss: 1.3581\n",
            "Epoch 54/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5547 - loss: 1.3669\n",
            "Epoch 55/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5578 - loss: 1.3726\n",
            "Epoch 56/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5587 - loss: 1.3670\n",
            "Epoch 57/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5568 - loss: 1.3707\n",
            "Epoch 58/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5621 - loss: 1.3552\n",
            "Epoch 59/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5602 - loss: 1.3637\n",
            "Epoch 60/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5563 - loss: 1.3727\n",
            "Epoch 61/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5625 - loss: 1.3547\n",
            "Epoch 62/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5613 - loss: 1.3591\n",
            "Epoch 63/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5600 - loss: 1.3607\n",
            "Epoch 64/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5594 - loss: 1.3584\n",
            "Epoch 65/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5564 - loss: 1.3652\n",
            "Epoch 66/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5600 - loss: 1.3559\n",
            "Epoch 67/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5579 - loss: 1.3601\n",
            "Epoch 68/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5592 - loss: 1.3613\n",
            "Epoch 69/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5575 - loss: 1.3688\n",
            "Epoch 70/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5623 - loss: 1.3578\n",
            "Epoch 71/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5615 - loss: 1.3561\n",
            "Epoch 72/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5565 - loss: 1.3607\n",
            "Epoch 73/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5612 - loss: 1.3610\n",
            "Epoch 74/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5617 - loss: 1.3598\n",
            "Epoch 75/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5570 - loss: 1.3608\n",
            "Epoch 76/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5601 - loss: 1.3574\n",
            "Epoch 77/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5602 - loss: 1.3591\n",
            "Epoch 78/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5591 - loss: 1.3606\n",
            "Epoch 79/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5593 - loss: 1.3647\n",
            "Epoch 80/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5585 - loss: 1.3612\n",
            "Epoch 81/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.5586 - loss: 1.3678\n",
            "Epoch 82/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5557 - loss: 1.3679\n",
            "Epoch 83/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5626 - loss: 1.3599\n",
            "Epoch 84/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5590 - loss: 1.3632\n",
            "Epoch 85/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5606 - loss: 1.3600\n",
            "Epoch 86/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5572 - loss: 1.3656\n",
            "Epoch 87/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5568 - loss: 1.3581\n",
            "Epoch 88/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5625 - loss: 1.3599\n",
            "Epoch 89/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5632 - loss: 1.3541\n",
            "Epoch 90/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5627 - loss: 1.3617\n",
            "Epoch 91/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5634 - loss: 1.3569\n",
            "Epoch 92/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5557 - loss: 1.3667\n",
            "Epoch 93/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5592 - loss: 1.3624\n",
            "Epoch 94/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5597 - loss: 1.3687\n",
            "Epoch 95/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5645 - loss: 1.3615\n",
            "Epoch 96/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5600 - loss: 1.3578\n",
            "Epoch 97/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5599 - loss: 1.3562\n",
            "Epoch 98/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5620 - loss: 1.3545\n",
            "Epoch 99/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5578 - loss: 1.3680\n",
            "Epoch 100/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5585 - loss: 1.3668\n",
            "Epoch 101/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5592 - loss: 1.3673\n",
            "Epoch 102/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5582 - loss: 1.3643\n",
            "Epoch 103/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5580 - loss: 1.3718\n",
            "Epoch 104/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5604 - loss: 1.3618\n",
            "Epoch 105/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5595 - loss: 1.3635\n",
            "Epoch 106/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5610 - loss: 1.3649\n",
            "Epoch 107/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5568 - loss: 1.3705\n",
            "Epoch 108/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5590 - loss: 1.3676\n",
            "Epoch 109/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5640 - loss: 1.3629\n",
            "Epoch 110/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5608 - loss: 1.3660\n",
            "Epoch 111/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5602 - loss: 1.3658\n",
            "Epoch 112/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5650 - loss: 1.3578\n",
            "Epoch 113/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5587 - loss: 1.3608\n",
            "Epoch 114/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5615 - loss: 1.3618\n",
            "Epoch 115/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5580 - loss: 1.3646\n",
            "Epoch 116/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5638 - loss: 1.3520\n",
            "Epoch 117/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5567 - loss: 1.3658\n",
            "Epoch 118/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5626 - loss: 1.3596\n",
            "Epoch 119/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5611 - loss: 1.3597\n",
            "Epoch 120/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5619 - loss: 1.3587\n",
            "Epoch 121/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5565 - loss: 1.3698\n",
            "Epoch 122/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5573 - loss: 1.3580\n",
            "Epoch 123/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5619 - loss: 1.3671\n",
            "Epoch 124/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5645 - loss: 1.3563\n",
            "Epoch 125/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5632 - loss: 1.3503\n",
            "Epoch 126/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5597 - loss: 1.3582\n",
            "Epoch 127/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5588 - loss: 1.3644\n",
            "Epoch 128/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5585 - loss: 1.3688\n",
            "Epoch 129/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5593 - loss: 1.3612\n",
            "Epoch 130/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5583 - loss: 1.3720\n",
            "Epoch 131/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5601 - loss: 1.3529\n",
            "Epoch 132/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5593 - loss: 1.3616\n",
            "Epoch 133/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5647 - loss: 1.3517\n",
            "Epoch 134/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5610 - loss: 1.3617\n",
            "Epoch 135/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5598 - loss: 1.3629\n",
            "Epoch 136/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5606 - loss: 1.3642\n",
            "Epoch 137/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5612 - loss: 1.3627\n",
            "Epoch 138/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5632 - loss: 1.3592\n",
            "Epoch 139/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5577 - loss: 1.3655\n",
            "Epoch 140/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5590 - loss: 1.3581\n",
            "Epoch 141/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5585 - loss: 1.3610\n",
            "Epoch 142/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5599 - loss: 1.3643\n",
            "Epoch 143/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5585 - loss: 1.3669\n",
            "Epoch 144/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5623 - loss: 1.3565\n",
            "Epoch 145/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5605 - loss: 1.3656\n",
            "Epoch 146/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5632 - loss: 1.3603\n",
            "Epoch 147/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5585 - loss: 1.3631\n",
            "Epoch 148/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5612 - loss: 1.3660\n",
            "Epoch 149/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5633 - loss: 1.3531\n",
            "Epoch 150/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5574 - loss: 1.3719\n",
            "Epoch 151/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5606 - loss: 1.3573\n",
            "Epoch 152/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5594 - loss: 1.3645\n",
            "Epoch 153/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5605 - loss: 1.3571\n",
            "Epoch 154/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5630 - loss: 1.3635\n",
            "Epoch 155/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5616 - loss: 1.3541\n",
            "Epoch 156/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5612 - loss: 1.3588\n",
            "Epoch 157/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5595 - loss: 1.3656\n",
            "Epoch 158/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5578 - loss: 1.3654\n",
            "Epoch 159/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5596 - loss: 1.3627\n",
            "Epoch 160/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5576 - loss: 1.3700\n",
            "Epoch 161/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5592 - loss: 1.3614\n",
            "Epoch 162/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5637 - loss: 1.3529\n",
            "Epoch 163/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5645 - loss: 1.3601\n",
            "Epoch 164/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5602 - loss: 1.3643\n",
            "Epoch 165/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5614 - loss: 1.3628\n",
            "Epoch 166/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5590 - loss: 1.3623\n",
            "Epoch 167/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5597 - loss: 1.3673\n",
            "Epoch 168/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5599 - loss: 1.3573\n",
            "Epoch 169/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5586 - loss: 1.3751\n",
            "Epoch 170/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5591 - loss: 1.3704\n",
            "Epoch 171/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5616 - loss: 1.3544\n",
            "Epoch 172/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5638 - loss: 1.3663\n",
            "Epoch 173/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5599 - loss: 1.3522\n",
            "Epoch 174/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5561 - loss: 1.3701\n",
            "Epoch 175/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5626 - loss: 1.3577\n",
            "Epoch 176/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5621 - loss: 1.3674\n",
            "Epoch 177/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5629 - loss: 1.3644\n",
            "Epoch 178/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5666 - loss: 1.3542\n",
            "Epoch 179/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5599 - loss: 1.3652\n",
            "Epoch 180/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5601 - loss: 1.3678\n",
            "Epoch 181/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5619 - loss: 1.3539\n",
            "Epoch 182/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5600 - loss: 1.3636\n",
            "Epoch 183/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5646 - loss: 1.3496\n",
            "Epoch 184/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5658 - loss: 1.3532\n",
            "Epoch 185/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5622 - loss: 1.3625\n",
            "Epoch 186/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5612 - loss: 1.3575\n",
            "Epoch 187/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5594 - loss: 1.3616\n",
            "Epoch 188/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5648 - loss: 1.3513\n",
            "Epoch 189/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.5615 - loss: 1.3638\n",
            "Epoch 190/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5586 - loss: 1.3638\n",
            "Epoch 191/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.5638 - loss: 1.3598\n",
            "Epoch 192/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5603 - loss: 1.3671\n",
            "Epoch 193/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5582 - loss: 1.3602\n",
            "Epoch 194/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5616 - loss: 1.3629\n",
            "Epoch 195/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5636 - loss: 1.3586\n",
            "Epoch 196/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5591 - loss: 1.3592\n",
            "Epoch 197/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5630 - loss: 1.3568\n",
            "Epoch 198/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5623 - loss: 1.3575\n",
            "Epoch 199/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5607 - loss: 1.3600\n",
            "Epoch 200/200\n",
            "\u001b[1m1154/1154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5603 - loss: 1.3610\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f44dd9f8fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD6SIafXCYbb"
      },
      "source": [
        "# Evaluación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "z7UV-B3eCYbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39539875-768f-4e76-a6d5-f2110c966614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "NEXT|55|i\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "NEXT|70|y\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "NEXT|8|.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "NEXT|2|!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "NEXT|47|a\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "NEXT|47|a\n",
            "princiy.!aaaaaaaaaaaaaaaa\n"
          ]
        }
      ],
      "source": [
        "seed = \"princ\"\n",
        "result = seed\n",
        "seed_data = [encode_keys[char]/(vocab_size - 1) for char in seed]\n",
        "for i in range(20):\n",
        "  predict_data = np.reshape(np.array(seed_data), (1, len(seed_data), 1))\n",
        "  prediction = vect_model.predict(predict_data)\n",
        "\n",
        "  index = np.argmax(prediction)\n",
        "  next_char = decode_keys[index]\n",
        "  result += next_char\n",
        "  print(\"NEXT\",index,next_char,sep=\"|\")\n",
        "\n",
        "  seed_data.append(encode_keys[char]/(vocab_size - 1))\n",
        "  seed_data = seed_data[1:] #Remove first element to move window along sequence\n",
        "\n",
        "  if ( (next_char == \" \")or(next_char == \"\\n\") ):\n",
        "    break\n",
        "\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}